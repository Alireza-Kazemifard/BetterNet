import os
import argparse
import numpy as np
import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.optimizers import Adam
from metrics import dice_coefficient, intersection_over_union, binary_crossentropy_dice_loss, weighted_f_score, s_score, e_score
from model import BetterNet
from utils import create_directory
from data import load_data, tf_dataset

if __name__ == "__main__":
    np.random.seed(42)
    tf.random.set_seed(42)

    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset_paths", nargs='+', required=True)
    parser.add_argument("--save_dir", type=str, required=True)
    parser.add_argument("--num_epochs", type=int, default=100)
    parser.add_argument("--batch_size", type=int, default=8)
    parser.add_argument("--learning_rate", type=float, default=1e-4)
    args = parser.parse_args()

    create_directory(args.save_dir)
    model_path = os.path.join(args.save_dir, "model.keras")
    csv_path = os.path.join(args.save_dir, "training_log.csv")

    print(f"ğŸ”„ Loading data from: {args.dataset_paths}")
    (train_x, train_y), (valid_x, valid_y) = load_data(args.dataset_paths, split=0.1)
    
    print(f"Stats: Training on {len(train_x)} images, Validating on {len(valid_x)} images.")

    # Ø¯ÛŒØªØ§Ø³Øª
    train_dataset = tf_dataset(train_x, train_y, batch_size=args.batch_size, augment=True, shuffle=True)
    valid_dataset = tf_dataset(valid_x, valid_y, batch_size=args.batch_size, augment=False, shuffle=False)

    # Ù…Ø¯Ù„ - Ø·Ø¨Ù‚ Ù…Ù‚Ø§Ù„Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ú©ÙˆØ¯Ø± ÙØ±ÛŒØ² Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
    # Ø§Ú¯Ø± Ù‡Ù…Ú¯Ø±Ø§ÛŒÛŒ Ø¶Ø¹ÛŒÙ Ø¨ÙˆØ¯ØŒ freeze_encoder=False Ø±Ø§ ØªØ³Øª Ú©Ù†ÛŒØ¯
    model = BetterNet(input_shape=(224, 224, 3), num_classes=1, dropout_rate=0.5, freeze_encoder=False) 
    # Ù†Ú©ØªÙ‡: Ù…Ù† Ø§ÛŒÙ†Ø¬Ø§ False Ú¯Ø°Ø§Ø´ØªÙ… Ú†ÙˆÙ† Ù…Ø¹Ù…ÙˆÙ„Ø§ Ø¯Ø± Ø¹Ù…Ù„ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ Ú©Ù…ØŒ Fine-tuning (Ø¨Ø§ Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù¾Ø§ÛŒÛŒÙ†) Ø¨Ù‡ØªØ± Ø¬ÙˆØ§Ø¨ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
    # Ø§Ú¯Ø± Ù…ÛŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚Ø§ Ø¬Ù…Ù„Ù‡ Ù…Ù‚Ø§Ù„Ù‡ Ø±Ø§ ØªØ³Øª Ú©Ù†ÛŒØ¯ØŒ True Ú©Ù†ÛŒØ¯.

    model.compile(
        optimizer=Adam(learning_rate=args.learning_rate),
        loss=binary_crossentropy_dice_loss,
        metrics=[dice_coefficient, intersection_over_union, weighted_f_score, s_score, e_score]
    )

    callbacks = [
        ModelCheckpoint(model_path, verbose=1, save_best_only=True, monitor='val_loss'),
        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-7, verbose=1),
        CSVLogger(csv_path),
        EarlyStopping(monitor='val_loss', patience=25, restore_best_weights=True)
    ]

    print("ğŸš€ Starting Training Process...")
    model.fit(
        train_dataset,
        epochs=args.num_epochs,
        validation_data=valid_dataset,
        callbacks=callbacks
    )
