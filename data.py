import os
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
import tensorflow as tf
from glob import glob

IMAGE_HEIGHT = 224
IMAGE_WIDTH = 224

def load_data(dataset_paths, split=0.1):
    images = []
    masks = []

    if isinstance(dataset_paths, str):
        dataset_paths = [dataset_paths]

    print("ğŸ“Š Loading data paths...")
    for path in dataset_paths:
        # Ø¬Ø³ØªØ¬ÙˆÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ù¾Ø³ÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        curr_images = sorted(glob(os.path.join(path, "images", "*")))
        curr_masks = sorted(glob(os.path.join(path, "masks", "*")))
        
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ù¾Ø³ÙˆÙ†Ø¯Ù‡Ø§ÛŒ Ù…Ø¬Ø§Ø²
        valid_exts = ('.png', '.jpg', '.jpeg', '.bmp', '.tif')
        curr_images = [x for x in curr_images if x.lower().endswith(valid_exts)]
        curr_masks = [x for x in curr_masks if x.lower().endswith(valid_exts)]
        
        # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¨Ø±Ø§Ø¨Ø± Ø¨ÙˆØ¯Ù† ØªØ¹Ø¯Ø§Ø¯
        min_len = min(len(curr_images), len(curr_masks))
        curr_images = curr_images[:min_len]
        curr_masks = curr_masks[:min_len]

        if len(curr_images) > 0:
             print(f"   Found {len(curr_images)} pairs in {path}")
             images.extend(curr_images)
             masks.extend(curr_masks)

    # Ø´Ø§ÙÙ„ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    train_x, valid_x, train_y, valid_y = train_test_split(images, masks, test_size=split, random_state=42)
    return (train_x, train_y), (valid_x, valid_y)

def read_image(path):
    path = path.decode()
    x = cv2.imread(path, cv2.IMREAD_COLOR)
    # Ø·Ø¨Ù‚ Ù…Ù‚Ø§Ù„Ù‡ Ùˆ Ú©Ø¯ Ù‚Ø¯ÛŒÙ…: ØªØºÛŒÛŒØ± Ø³Ø§ÛŒØ² Ø¨Ø§ Lanczos4
    x = cv2.resize(x, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_LANCZOS4)
    # Ø§ØµÙ„Ø§Ø­ Ø­ÛŒØ§ØªÛŒ: Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ù‡ 0 ØªØ§ 1
    x = x / 255.0
    return x.astype(np.float32)

def read_mask(path):
    path = path.decode()
    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    x = cv2.resize(x, (IMAGE_WIDTH, IMAGE_HEIGHT), interpolation=cv2.INTER_LANCZOS4)
    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù…Ø§Ø³Ú©
    x = x / 255.0
    x = np.expand_dims(x, axis=-1)
    # Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ú©Ø±Ø¯Ù† Ù…Ø§Ø³Ú©
    x = np.where(x > 0.5, 1.0, 0.0)
    return x.astype(np.float32)

def tf_parse(x, y):
    def _parse(x, y):
        x = read_image(x)
        y = read_mask(y)
        return x, y
    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])
    x.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, 3])
    y.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, 1])
    return x, y

def tf_dataset(X, Y, batch_size=8, augment=False, shuffle=False):
    dataset = tf.data.Dataset.from_tensor_slices((X, Y))
    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)
    
    if shuffle:
        dataset = dataset.shuffle(buffer_size=len(X))
        
    if augment:
        # Ø¯Ø§Ø¯Ù‡â€ŒØ§ÙØ²Ø§ÛŒÛŒ Ø³Ø§Ø¯Ù‡ (Flipping) Ù…Ø´Ø§Ø¨Ù‡ Ù…Ù‚Ø§Ù„Ù‡
        dataset = dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), tf.image.random_flip_left_right(y)))
        dataset = dataset.map(lambda x, y: (tf.image.random_flip_up_down(x), tf.image.random_flip_up_down(y)))
        
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)
    return dataset
